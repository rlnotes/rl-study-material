## List of Papers of interest

### ICML 2017
* Unifying task specification in reinforcement learning[[Paper](https://arxiv.org/abs/1609.01995)]
  * Martha White (University of Alberta/Indiana University)

* FeUdal Networks for Hierarchical Reinforcement Learning[[Paper](https://arxiv.org/abs/1703.01161)]
  * Alexander Vezhnevets (DeepMind) · Simon Osindero (DeepMind) · Tom Schaul (DeepMind) · Nicolas Heess (Google DeepMind) · Max Jaderberg (DeepMind) · David Silver (Google DeepMind) · Koray Kavukcuoglu (DeepMind)

* Modular Multitask Reinforcement Learning with Policy Sketches[[Paper](https://arxiv.org/abs/1611.01796)]
  * Jacob Andreas (UC Berkeley) · Dan Klein (UC Berkeley) · Sergey Levine (Berkeley)

* Averaged-DQN: Variance Reduction and Stabilization for Deep Reinforcement Learning[[Paper](https://pdfs.semanticscholar.org/a200/f7bc6a7c59e3c8fd8111792e98423809c577.pdf)]
  * Oron Anschel (Technion) · Nir Baram (Technion - Israel Institute of Technology) · Nahum Shimkin (Technion)

* A Laplacian Framework for Option Discovery in Reinforcement Learning[[Paper](https://arxiv.org/abs/1703.00956)]
  * Marlos C. Machado (University of Alberta) · Marc Bellemare (DeepMind) · Michael Bowling (University of Alberta)

* A Distributional Perspective on Reinforcement Learning
  * Marc Bellemare (DeepMind) · Will Dabney (DeepMind) · Remi Munos (DeepMind)

* End-to-End Differentiable Adversarial Imitation Learning[[Slide](http://icri-ci.technion.ac.il/files/2017/05/14-Shie-Mannor-170509.pdf)]
  * Nir Baram (Technion - Israel Institute of Technology) · Oron Anschel (Technion) · Itai Caspi (Technion) · Shie Mannor (Technion)

* (Even More) Efficient Reinforcement Learning via Posterior Sampling
  * Ian Osband (Deepmind) · Benjamin Van Roy (Stanford University)

* Fairness in Reinforcement Learning[[Paper](http://www.cis.upenn.edu/~mkearns/papers/FairRL.pdf)]
  * Shahin Jabbari (University of Pennsylvania) · Matthew Joseph (University of Pennsylvania) · Michael Kearns (University of Pennsylvania) · Jamie Morgenstern (University of Pennsylvania) · Aaron Roth (University of Pennsylvania)

* DARLA: Improving Zero-Shot Transfer in Reinforcement Learning
  * Irina Higgins (DeepMind) · Arka Pal (DeepMind) · Andrei A Rusu (DeepMind) · Loic Matthey (DeepMind) · Christopher Burgess (DeepMind) · Alexander Pritzel (Deepmind) · Matthew Botvinick (DeepMind) · Charles Blundell (DeepMind) · Alexander Lerchner (DeepMind)

* Improving Stochastic Policy Gradients in Continuous Control with Deep Reinforcement Learning using the Beta Distribution
  * Po-Wei Chou (Carnegie Mellon University) · Daniel Maturana (Carnegie Mellon University) · Sebastian Scherer (Carnegie Mellon University)

* Robust Adversarial Reinforcement Learning[[Paper](https://arxiv.org/abs/1703.02702)]
  * Lerrel Pinto (Carnegie Mellon University) · James Davidson (Google Brain) · Rahul Sukthankar (Google Research) · Abhinav Gupta (Carnegie Mellon University)

* Minimax Regret Bounds for Reinforcement LEarning[[Paper](https://arxiv.org/abs/1703.05449)]
  * Mohammad Gheshlaghi Azar (Deepmind) · Ian Osband (Google DeepMind) · Remi Munos (DeepMind)

* Stabilising Experience Replay for Deep Multi-Agent Reinforcement Learning[[Paper](https://arxiv.org/abs/1702.08887)]
  * Jakob Foerster (University of Oxford) · Nantas Nardelli (University of Oxford) · Gregory Farquhar (University of Oxford) · Triantafyllos Afouras (University of Oxford) · Phil Torr (Oxford) · Pushmeet Kohli (Microsoft Research) · Shimon Whiteson (University of Oxford)

* An Alternative Softmax Operator for Reinforcement Learning[[Paper](https://arxiv.org/abs/1612.05628)]
  * Kavosh Asadi (Brown University) · Michael L. Littman (Brown University)

* Zero-Shot Task Generalization with Multi-Task Deep Reinforcement Learning[[Paper](https://arxiv.org/abs/1706.05064)]
  * Junhyuk Oh (University of Michigan) · Satinder Singh (University of Michigan) · Honglak Lee (Google / U. Michigan) · Pushmeet Kohli (Microsoft Research)

* Reinforcement Learning with Deep Energy-Based Policies[[Paper](https://arxiv.org/abs/1702.08165)]
  * Tuomas Haarnoja (UC Berkeley) · Haoran Tang (UC Berkeley) · Pieter Abbeel (OpenAI / UC Berkeley) · Sergey Levine (Berkeley)

* Neural Optimizer Search using Reinforcement Learning[[Paper](https://research.google.com/pubs/pub46114.html)]
  * Irwan Bello (Google Brain) · Barret Zoph (Google) · Vijay Vasudevan (Google) · Quoc Le (Google Brain)

* Deep Decentralized Multi-task Multi-Agent Reinforcement Learning under Partial Observability[[Paper](https://arxiv.org/abs/1703.06182)]
  * Shayegan Omidshafiei (MIT) · Jason Pazis (Amazon) · Chris Amato (Northeastern University) · Jonathan How (MIT) · John L Vian (The Boeing Company)

* Combining Model-Based and Model-Free Updates for Trajectory-Centric Reinforcement Learning[[Paper](https://arxiv.org/abs/1703.03078)]
  * Yevgen Chebotar (University of Southern California) · Karol Hausman (University of Southern California) · Marvin Zhang (UC Berkeley) · Gaurav Sukhatme (University of Southern California) · Stefan Schaal () · Sergey Levine (Berkeley)

* Counterfactual Data-Fusion for Online Reinforcement Learners[[Paper](http://ftp.cs.ucla.edu/pub/stat_ser/r471.pdf)]
  * Andrew Forney (UCLA) · Judea Pearl (UCLA) · Elias Bareinboim (Purdue)

* Device Placement Optimization with Reinforcement Learning [[Paper](https://arxiv.org/abs/1706.04972)]
  * Azalia Mirhoseini (Google) · Hieu Pham (Google) · Quoc Le (Google Brain) · benoit steiner (Google) · Mohammad Norouzi (Google) · Rasmus Larsen (Google) · Yuefeng Zhou (Google Brain) · Naveen Kumar (Google) · Samy Bengio (Google Brain) · Jeff Dean (Google Brain)